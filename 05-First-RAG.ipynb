{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76fbaf88-5952-47bf-a68c-85011e49b6de",
   "metadata": {},
   "source": [
    "# Building our First RAG bot - Skill: talk to Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c3b06-c8a0-45db-be9a-974c762ba4b8",
   "metadata": {},
   "source": [
    "We have now all the building blocks to build our first Bot that \"talks with my data\". These blocks are:\n",
    "\n",
    "1) A well indexed hybrid (text and vector) engine with my data in chunks -> Azure AI Search\n",
    "2) A good LLM python framework to build LLM Apps -> LangChain\n",
    "3) Quality OpenAI GPT models that understand language and follow instructions -> GPT3.5 and GPT4\n",
    "4) A persisten memory database -> CosmosDB\n",
    "\n",
    "We are missing just one thing: **Agents**.\n",
    "\n",
    "In this Notebook we introduce the concept of Agents and we use it to build or first RAG bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1475b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci-aoai-testing/code\n",
      "Logs\n",
      "Users\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "dir_list = os.listdir(current_directory)\n",
    "\n",
    "for item in dir_list:\n",
    "    print(item)\n",
    "\n",
    "os.chdir('Users/hkjung/Azure-AI-Search-Azure-OpenAI-Workbench/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64f701d-5b9d-4c7c-b259-c2a515c75961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import asyncio\n",
    "from typing import Dict, List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField, ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import  GetDocSearchResults_Tool\n",
    "from common.prompts import AGENT_DOCSEARCH_PROMPT\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4163af7-39d0-43b4-8dad-c13108d22a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33836104-822e-4846-8b81-0de8e24838f1",
   "metadata": {},
   "source": [
    "## Introducing: Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc3d38-93f8-4a47-8125-d1bb9f529178",
   "metadata": {},
   "source": [
    "The implementation of Agents is inspired by two papers: the [MRKL Systems](https://arxiv.org/abs/2205.00445) paper (pronounced â€˜miracleâ€™ ðŸ˜‰) and the [ReAct](https://arxiv.org/abs/2210.03629) paper.\n",
    "\n",
    "Agents are a way to leverage the ability of LLMs to understand and act on prompts. In essence, an Agent is an LLM that has been given a very clever initial prompt. The prompt tells the LLM to break down the process of answering a complex query into a sequence of steps that are resolved one at a time.\n",
    "\n",
    "Agents become really cool when we combine them with â€˜expertsâ€™, introduced in the MRKL paper. Simple example: an Agent might not have the inherent capability to reliably perform mathematical calculations by itself. However, we can introduce an expert - in this case a calculator, an expert at mathematical calculations. Now, when we need to perform a calculation, the Agent can call in the expert rather than trying to predict the result itself. This is actually the concept behind [ChatGPT Pluggins](https://openai.com/blog/chatgpt-plugins).\n",
    "\n",
    "In our case, in order to solve the problem \"How do I build a smart bot that talks to my data\", we need this REACT/MRKL approach, in which we need to instruct the LLM that it needs to use 'experts/tools' in order to read/load/understand/interact with a any particular source of data.\n",
    "\n",
    "Let's create then an Agent that interact with the user and uses a Tool to get the information from the Search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7999a06-aff0-4d21-8be7-fe56c70082a8",
   "metadata": {},
   "source": [
    "#### We start first defining the Tool/Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a862366b-ce9e-44f8-9610-84ec568653ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-hrdocs\"\n",
    "index2_name = \"cogsrch-index-techdocs\"\n",
    "indexes = [index1_name, index2_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077886c8-c5d0-481d-a5f9-f4becf60e0f9",
   "metadata": {},
   "source": [
    "We have to convert the Retreiver object into a Tool object (\"the expert\"). Check out the Tool `GetDocSearchResults_Tool` in `utils.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c6ca7-d93b-4961-b90a-08572cad78d8",
   "metadata": {},
   "source": [
    "Declare the tools the agent will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0fd3a0-527c-42e3-a092-46e03d33bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK=7\n",
    "tools = [GetDocSearchResults_Tool(indexes=indexes, k=5, description=\"It is useful for searching technical information about Azure AI Search Service\", reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6797e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our Tools/Experts\n",
    "hrdocs_indexes = [\"cogsrch-index-hrdocs\"]\n",
    "hrdocs_search = GetDocSearchResults_Tool(name=\"hrdocs\", indexes=indexes, k=5, description=\"It is useful for searching company information about health benefit, policies of company, roles description\", reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])\n",
    "\n",
    "techdocs_indexes = [\"cogsrch-index-techdocs\"]\n",
    "techdocs_search = GetDocSearchResults_Tool(name=\"techdocs\", indexes=indexes, k=5, description=\"It is useful for searching technical information about Azure Service like Azure AI Search, Azure AI Services\", reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])\n",
    "\n",
    "topK=7\n",
    "tools = [hrdocs_search, techdocs_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cac295-8be5-4803-8342-6d4e48cd2294",
   "metadata": {},
   "source": [
    "Get the prompt to use `AGENT_DOCSEARCH_PROMPT` - you can modify this in `prompts.py`! Check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a44f8df6-a68e-4215-99f3-10119f796c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = AGENT_DOCSEARCH_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ddf18-3f3c-44b4-8af5-1437973da010",
   "metadata": {},
   "source": [
    "Define the LLM to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aaaf7f5-ef26-48d8-868d-b53aa4c4f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 1500\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True).configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    default_key=\"gpt35\",\n",
    "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d527c12-4e18-4f3f-a9ec-8dab4f9ca7b2",
   "metadata": {},
   "source": [
    "Construct the OpenAI Tools agent.\n",
    "> OpenAI API has deprecated functions in favor of tools. The difference between the two is that the tools API allows the model to request that multiple functions be invoked at once, which can reduce response times in some architectures. Itâ€™s recommended to use the tools agent for OpenAI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fff2766-defb-45fc-b271-3c811077076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt35\"}), tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338336d9-a64a-4602-908a-742b418e4520",
   "metadata": {},
   "source": [
    "Create an agent executor by passing in the agent and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6c156f-9a17-4daa-80de-70ce2f55063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a017c-3b36-43ab-8633-78f4f005d166",
   "metadata": {},
   "source": [
    "Give it memory - since AgentExecutor is also a Runnable class, we do the same with did on Notebook 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c013314-afe6-4218-b179-d0f7312d2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df017f-3ab7-4943-adc1-3477badf3d3e",
   "metadata": {},
   "source": [
    "Because cosmosDB needs two fields (an id and a partition), and RunnableWithMessageHistory takes by default only one identifier for memory (session_id), we need to use `history_factory_config` parameter and define the multiple keys for the memory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf93758f-da3b-48fb-9882-91fe327b1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_spec = ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )\n",
    "session_id = ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d1aaa6-efca-4512-b680-896dae39a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[userid_spec,session_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c6b489-3db9-4965-9eae-ed2790e62bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'session143', 'user_id': 'user945'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295c54e-a5e2-46f6-99fc-6f76453a877d",
   "metadata": {},
   "source": [
    "Run the Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac81763-6bcc-4408-9daf-d047a0e2cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 233 ms, sys: 532 Âµs, total: 234 ms\n",
      "Wall time: 3.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Hi, I'm Pablo Marin. What's yours\",\n",
       " 'history': [],\n",
       " 'output': \"Hello Pablo Marin, I'm Jarvis. How can I assist you today?\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "agent_with_chat_history.invoke({\"question\": \"Hi, I'm Pablo Marin. What's yours\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb3fca7e-33a1-40f1-afb0-dee441a1d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Once an Azure AI Search index or service is deleted, it cannot be recovered. When you delete a search service, all indexes in the service are permanently deleted<sup><a href=\"https://blobstorage2znp775rdhyvo.blob.core.windows.net/techdocs/Azure_Cognitive_Search_Documentation_Overview.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-04-29T18:11:18Z&st=2024-03-17T10:11:18Z&spr=https&sig=qtSFdHgO4IxArZIDQZbvcc2T7Q4INFsy7XZiIjOqWE0%3D\">[1]</a></sup>.\n",
       "\n",
       "If you want to move an index between search services, you can try using the index-backup-restore sample code in the Azure AI Search .NET sample repository. There is also a Python version available for backup and restore<sup><a href=\"https://blobstorage2znp775rdhyvo.blob.core.windows.net/techdocs/Azure_Cognitive_Search_Documentation_Overview.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-04-29T18:11:18Z&st=2024-03-17T10:11:18Z&spr=https&sig=qtSFdHgO4IxArZIDQZbvcc2T7Q4INFsy7XZiIjOqWE0%3D\">[1]</a></sup>.\n",
       "\n",
       "In summary, once deleted, an Azure AI Search index or service cannot be restored, and it is recommended to use the backup and restore functionality if you need to move an index between search services."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke(\n",
    "    {\"question\": \"Can I restore my index or service once it's deleted?\"}, \n",
    "    config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c430c456-f390-4319-a3b1-bee19da130cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "There's no native support for porting indexes in Azure AI Search. Search indexes are considered downstream data structures, accepting content from other data sources that collect operational data. As such, there's no built-in support for backing up and restoring indexes because the expectation is that you would rebuild an index from source data if you deleted it or wanted to move it<sup><a href=\"https://blobstorage2znp775rdhyvo.blob.core.windows.net/techdocs/Azure_Cognitive_Search_Documentation_Overview.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-04-29T18:11:18Z&st=2024-03-17T10:11:18Z&spr=https&sig=qtSFdHgO4IxArZIDQZbvcc2T7Q4INFsy7XZiIjOqWE0%3D\">[1]</a></sup>.\n",
       "\n",
       "However, if you want to move an index between search services, you can try using the index-backup-restore sample code in the Azure AI Search .NET sample repository. There is also a Python version available for backup and restore<sup><a href=\"https://blobstorage2znp775rdhyvo.blob.core.windows.net/techdocs/Azure_Cognitive_Search_Documentation_Overview.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-04-29T18:11:18Z&st=2024-03-17T10:11:18Z&spr=https&sig=qtSFdHgO4IxArZIDQZbvcc2T7Q4INFsy7XZiIjOqWE0%3D\">[1]</a></sup>.\n",
       "\n",
       "In summary, while there is no native support for moving, backing up, or restoring indexes in Azure AI Search, you can use sample code provided in the .NET and Python repositories to achieve this functionality."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    printmd(agent_with_chat_history.invoke(\n",
    "        {\"question\": \"Interesting, Can I move, backup, and restore indexes?\"},\n",
    "        config=config)[\"output\"])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fd54f71-03c9-4332-885b-0d1df942fa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You're welcome! If you have any other questions, feel free to ask."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke({\"question\": \"Thank you!\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149648ba-945d-4e7d-81f7-a8bca2ac87f2",
   "metadata": {},
   "source": [
    "#### Important: there is a limitation of GPT3.5, once we start adding long prompts, and long contexts and thorough answers, or the agent makes multiple searches for multi-step questions, we run out of space!\n",
    "\n",
    "You can minimize this by:\n",
    "- Shorter System Prompt\n",
    "- Smaller chunks (less than the default of 5000 characters)\n",
    "- Reducing topK to bring less relevant chunks\n",
    "\n",
    "However, you ultimately are sacrificing quality to make everything work with GPT3.5 (cheaper and faster model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41787714-73fd-4336-85f2-bec3abb41eda",
   "metadata": {},
   "source": [
    "### Let's add more things we have learned so far: dynamic LLM selection of GPT4 and asyncronous streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1511d2c3-97fe-4232-a560-014d0f157008",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt4\"}), tools, prompt) # We select now GPT-4\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "agent_with_chat_history = RunnableWithMessageHistory(agent_executor,get_session_history,input_messages_key=\"question\", \n",
    "                                                     history_messages_key=\"history\", history_factory_config=[userid_spec,session_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec5b32-6017-44b9-97e7-34ba3695e688",
   "metadata": {},
   "source": [
    "In prior notebooks with use the function `.stream()` of the runnable in order to stream the tokens. However if you need to stream individual tokens from the agent or surface steps occuring within tools, you would need to use a combination of `Callbacks` and `.astream()` OR the new `astream_events` API (beta).\n",
    "\n",
    "Letâ€™s use here the astream_events API to stream the following events:\n",
    "\n",
    "    Agent Start with inputs\n",
    "    Tool Start with inputs\n",
    "    Tool End with outputs\n",
    "    Stream the agent final anwer token by token\n",
    "    Agent End with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9600a35e-8d2e-43d0-a334-092b2e8b832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What is Azure AI Search?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3808fa33-05bb-4f5d-9ab9-7159f6db62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure AI Search is a service that provides a dedicated search engine and persistent storage for your searchable content, supporting full text and vector search scenarios. It includes optional integrated AI to extract more text and structure from raw content, and to chunk and vectorize content for vector search. The service is designed to be used programmatically, with support provided through REST APIs and client libraries in .NET, Python, Java, and JavaScript SDKs for Azure<sup><a href=\"https://blobstorage2znp775rdhyvo.blob.core.windows.net/techdocs/Azure_Cognitive_Search_Documentation_Overview.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-04-29T18:11:18Z&st=2024-03-17T10:11:18Z&spr=https&sig=qtSFdHgO4IxArZIDQZbvcc2T7Q4INFsy7XZiIjOqWE0%3D\" target=\"_blank\">[1]</a></sup>.\n",
      "\n",
      "Azure AI Search is well-suited for various application scenarios, including:\n",
      "\n",
      "- Search over vector and text content, isolated from the internet.\n",
      "- Consolidation of heterogeneous content into a user-defined and populated search index composed of vectors and text.\n",
      "- Integration of data chunking and vectorization for generative AI and Retrieval-Augmented Generation (RAG) apps.\n",
      "- Application of granular access control at the document level.\n",
      "- Offloading indexing and query workloads onto a dedicated search service.\n",
      "- Implementation of search-related features such as relevance tuning, faceted navigation, filters (including geo-spatial search), synonym mapping, and autocomplete<sup><a href=\"https://blobstorage2znp775rdhyvo.blob.core.windows.net/techdocs/Azure_Cognitive_Search_Documentation_Overview.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-04-29T18:11:18Z&st=2024-03-17T10:11:18Z&spr=https&sig=qtSFdHgO4IxArZIDQZbvcc2T7Q4INFsy7XZiIjOqWE0%3D\" target=\"_blank\">[2]</a></sup>.\n",
      "\n",
      "The service was formerly known as \"Azure Cognitive Search\" but was renamed to Azure AI Search in October 2023 to align with Azure AI services. It is designed to work with capabilities such as full text and vector search over a search index, rich indexing with integrated data chunking and vectorization, and rich query syntax for various search types. Azure AI Search integrates well with the Azure platform, including data layer integration, machine learning, Azure AI services, and Azure OpenAI<sup><a href=\"https://blobstorage2znp775rdhyvo.blob.core.windows.net/techdocs/Azure_Cognitive_Search_Documentation_Overview.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-04-29T18:11:18Z&st=2024-03-17T10:11:18Z&spr=https&sig=qtSFdHgO4IxArZIDQZbvcc2T7Q4INFsy7XZiIjOqWE0%3D\" target=\"_blank\">[3]</a></sup>."
     ]
    }
   ],
   "source": [
    "async for event in agent_with_chat_history.astream_events(\n",
    "    {\"question\": QUESTION}, config=config, version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    # if kind == \"on_chain_start\":\n",
    "    #     if (\n",
    "    #         event[\"name\"] == \"AgentExecutor\"\n",
    "    #     ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "    #         print(\n",
    "    #             f\"Starting agent: {event['name']}\"\n",
    "    #         )\n",
    "    # elif kind == \"on_chain_end\":\n",
    "    #     if (\n",
    "    #         event[\"name\"] == \"AgentExecutor\"\n",
    "    #     ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "    #         print()\n",
    "    #         print(\"--\")\n",
    "    #         print(\n",
    "    #             f\"Done agent: {event['name']}\"\n",
    "    #         )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"\")\n",
    "    # elif kind == \"on_tool_start\":\n",
    "    #     print(\"--\")\n",
    "    #     print(\n",
    "    #         f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "    #     )\n",
    "    # elif kind == \"on_tool_end\":\n",
    "    #     print(f\"Done tool: {event['name']}\")\n",
    "    #     # print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "    #     print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41bba7-18df-4ab8-b4f6-60368160d348",
   "metadata": {},
   "source": [
    "#### Note: Try to run this last question with GPT3.5 and see how you are going to run out of token space in the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec64bf-fe24-42fc-8dde-4d478f0af21e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We just built our first RAG BOT!.\n",
    "\n",
    "- We learned that **Agents + Tools are the best way to go about building Bots**. <br>\n",
    "- We converted the Azure Search retriever into a Tool using the function `GetDocSearchResults_Tool` in `utils.py`\n",
    "- We learned about the events API (Beta), one way to stream the answer from agents\n",
    "- We learned that for comprehensive, quality answers we will run out of space with GPT3.5. GPT4 then becomes necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56306506-d53d-4d43-93e2-a9300ed2a3ee",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "\n",
    "Now that we have a bot with one skill (Document Search), let's build more skills!. In the next Notebook, we will guide you on how we stick everything together. How do we use the features of all notebooks and create a brain agent that can respond to any request accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
